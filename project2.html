<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>FER | Victor Cárdenas</title>
  <link rel="stylesheet" href="styles.css">
  <!-- GSAP for animations -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.4/gsap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.11.4/ScrollTrigger.min.js"></script>
  <!-- Inter Font -->
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600&display=swap">
</head>
<body>
  <!-- Loading Overlay -->
  <div class="loader">
    <div class="loader__inner"></div>
  </div>

  <!-- Navigation -->
  <nav class="nav">
    <a href="index.html" class="nav__logo">
      <img src="logo_vic.png" alt="Victor Cárdenas Logo" class="nav__logo-image">
    </a>
    <div class="nav__menu">
      <a href="index.html" class="nav__item">Work</a>
      <a href="about.html" class="nav__item">About</a>
      <a href="cv.html" class="nav__item">CV</a>
      <a href="contact.html" class="nav__item">Contact</a>
    </div>
  </nav>
  
  <!-- Case Study Header -->
  <header class="case-header">
    <div class="case-header__content">
      <h1 class="case-header__title">
        <span class="line">Emotion Classification</span>
        <span class="line">Using Deep Learning</span>
      </h1>
      <div class="case-header__meta">
        <div class="case-meta__item">
          <h4>Role</h4>
          <p>Data Scientist</p>
        </div>
        <div class="case-meta__item">
          <h4>Year</h4>
          <p>2025</p>
        </div>
        <div class="case-meta__item">
          <h4>Client</h4>
          <p>Western Institute of Technology and Higher Education</p>
        </div>
      </div>
    </div>
  </header>

  <!-- Hero Image -->
  <div class="case-hero">
    <img src="project_4.png" alt="Project Hero Image" class="case-hero__image">
  </div>

  <!-- Case Study Content -->
  <main class="case-content">
    <!-- Introduction Section -->
    <section class="case-section">
      <div class="case-section__header">
        <h2 class="case-section__title">Introduction</h2>
      </div>
      <div class="case-section__content">
        <p class="case-text">Facial Expression Recognition (FER) is a branch of computer vision that seeks to interpret human emotions from facial cues. In this project, I developed a FER system capable of classifying Ekman’s seven universal emotions — anger, disgust, fear, happiness, sadness, surprise, and neutrality — by training a custom deep learning model on a high-quality, carefully curated dataset. The project blends classic and modern FER insights, aiming to make emotion recognition more accurate and accessible even with limited hardware.</p>
      </div>
    </section>

    <!-- Two Column Layout -->
    <section class="case-section case-section--two-column">
      <div class="case-column">
        <h3 class="case-column__title">The Challenge</h3>
        <p class="case-text">Most state-of-the-art FER models are trained on constrained datasets or require high-end resources to achieve competitive accuracy. Additionally, expression recognition tends to degrade under real-world conditions — such as varied lighting, subtle expressions, or domain shifts (e.g., from adults to children or from posed to spontaneous expressions).</p>
      </div>
      <div class="case-column">
        <h3 class="case-column__title">The Solution</h3>
        <p class="case-text">The project proposes a deep learning-based FER system trained on a hybrid dataset combining real, synthetic, and web-sourced images. The model architecture is based on a fine-tuned ResNet-18 with custom training strategies such as data augmentation, cosine annealing, and cross-domain data curation. This approach offers a balanced tradeoff between performance and resource efficiency.
        </p>
      </div>
    </section>

    <!-- Full Width Image -->
    <!-- <div class="case-image">
      <img src="con_matrix_7emotions.png" alt="Project Detail">
    </div> -->

<!-- Process Section -->
<section class="case-section">
  <div class="case-section__header">
    <h2 class="case-section__title">Process</h2>
  </div>
  <div class="case-section__content">
    <p class="case-text">The approach followed four essential phases:</p>

    <div class="case-process">
      <div class="case-process__item">
        <h4 class="case-process__step">01</h4>
        <h3 class="case-process__title">Problem Framing</h3>
        <p class="case-process__desc">Defined the classification goal (7 Ekman emotions), established hardware constraints, and set performance targets.</p>
      </div>
      <div class="case-process__item">
        <h4 class="case-process__step">02</h4>
        <h3 class="case-process__title">Dataset Development</h3>
        <p class="case-process__desc">Curated and manually reviewed ~2,000 high-quality images from multiple datasets and sources, ensuring emotion accuracy and consistency.</p>
      </div>
      <div class="case-process__item">
        <h4 class="case-process__step">03</h4>
        <h3 class="case-process__title">Model Training</h3>
        <p class="case-process__desc">Implemented a ResNet-18 architecture with data preprocessing, cosine learning rate scheduling, and reproducible training routines.</p>
      </div>
      <div class="case-process__item">
        <h4 class="case-process__step">04</h4>
        <h3 class="case-process__title">Evaluation & Benchmarking</h3>
        <p class="case-process__desc">Achieved 88% accuracy. Compared results with state-of-the-art models from recent FER literature.</p>
      </div>
    </div>
  </div>
</section>

    
    <!-- State of the Art -->

    <section class="case-section">
      <div class="case-section__header">
        <h2 class="case-section__title">State of the Art</h2>
      </div>
      <div class="case-section__content">
        <p class="case-text">A review of recent research highlights key trade-offs in FER model design:</p>
    
        <div class="case-process">
          <div class="case-process__item">
            <h3 class="case-process__title">Power = Precision</h3>
            <p class="case-process__desc">RRN + TST tops the charts (100% on CK+) — but demands serious computing power.</p>
          </div>
          <div class="case-process__item">
            <h3 class="case-process__title">Smart & Slim</h3>
            <p class="case-process__desc">MobileNetV2 + ResNet-18 delivers solid results (up to 86%) — perfect for limited hardware.</p>
          </div>
          <div class="case-process__item">
            <h3 class="case-process__title">Transformers Scale</h3>
            <p class="case-process__desc">ViT-based models generalize well but require more VRAM and longer training times.</p>
          </div>
          <div class="case-process__item">
            <h3 class="case-process__title">SVMs Fall Behind</h3>
            <p class="case-process__desc">Lightweight and simple, but classical SVMs struggle to keep up with deep learning models.</p>
          </div>
        </div>
      </div>
    </section>

    <!-- Theoretical Framework -->
    <section class="case-section">
          <div class="case-section__header">
            <h2 class="case-section__title">Theoretical Framework</h2>
          </div>
          <div class="case-section__content">
            <p class="case-text">The project is rooted in:</p>
          <ul class="case-text--list">
            <li>Ekman's theory of universal emotions (seven core emotions)</li>
            <li>Convolutional Neural Networks (CNNs) for spatial feature extraction</li>
            <li>Transfer Learning and Fine-tunin</li>
            <li>Cross-domain learning through dataset hybridization and augmentation</li>
          </ul>
        </div>
      </div>
    </section>


    <section class="case-section">
      <div class="case-section__header">
        <h2 class="case-section__title">Development and Methodology</h2>
      <div class="case-listing">
        <div class="case-listing__group">
          <h4>Dataset Development:</h4>
          <ul>
            <li>~2,000 manually reviewed images across seven emotion classes.</li>
            <li>Sources: FER-2013, AffectNet, Oulu-CASIA, MMI, web scraping, Meta & Gemini-generated faces.</li>
          </ul>
        </div>
      
        <div class="case-listing__group">
          <h4>Architecture Proposed:</h4>
          <ul>
            <li>ResNet-18 pretrained on ImageNet.</li>
            <li>Custom training loop with cosine LR scheduling and optional augmentations.</li>
          </ul>
        </div>
      
        <div class="case-listing__group">
          <h4>Resources Used:</h4>
          <ul>
            <li>Intel Core i7 (10th Gen)</li>
            <li>NVIDIA GTX 1650 Ti (4GB VRAM)</li>
            <li>Python, PyTorch, OpenCV, Albumentations</li>
          </ul>
        </div>
      </div>
        </div>
      </div>
    </section>
      

    <!-- Results Section -->
    <section class="case-section case-section--dark">
      <div class="case-section__header">
        <h2 class="case-section__title">Results</h2>
      </div>
      <div class="case-section__content">
        <div class="case-stats">
          <div class="case-stat">
            <h3 class="case-stat__value">88%</h3>
            <p class="case-stat__label">Overall accuracy across 1,498 validation samples.</p>
          </div>
          <div class="case-stat">
            <h3 class="case-stat__value">0.96 F1</h3>
            <p class="case-stat__label">Highest-scoring classes: <strong>Happy</strong> and <strong>Surprise</strong>.</p>
          </div>
          <div class="case-stat">
            <h3 class="case-stat__value">+2%↑</h3>
            <p class="case-stat__label">Outperformed average ResNet-18 FER models (typically ~86%) on FER2013-like datasets.</p>
          </div>
        </div>
        <p class="case-text">
          Compared to similar studies using ResNet-18 and MobileNetV2 on FER2013 and mixed datasets, which reported F1-scores ranging from 84% to 86%, this implementation achieved a consistent <strong>macro F1-score of 88%</strong>. The model showed excellent class-wise performance in <em>Happy</em> and <em>Surprise</em>, confirming its effectiveness despite limited resources.
        </p>
      </div>
    </section>


    <!-- Gallery Section -->
    <!-- <section class="case-gallery">
      <div class="case-gallery__item">
        <img src="con_matrix_7emotions.png" alt="Project Gallery Image 1">
      </div>
      <div class="case-gallery__item">
        <img src="project_gallery_2.jpg" alt="Project Gallery Image 2">
      </div>
    </section> -->

    <!-- Theoretical Framework -->
    <section class="case-section">
      <div class="case-section__header">
        <h2 class="case-section__title">Next Steps</h2>
      </div>
      <ul class="case-text--list">
        <li>Add emotion intensity and arousal-valence labeling.</li>
        <li>Extend training to temporal data (videos) using LSTM or 3D CNNs.</li>
        <li>Deploy the model in a lightweight desktop app or mobile tool for psychology, education, or HCI applications.</li>
        <li>Evaluate performance on datasets like VFEM or AffWild2 for deeper mental health analysis integration.</li>
      </ul>
    </section>

    <!-- Next Project CTA -->
    <section class="case-cta">
      <div class="case-cta__content">
        <h3 class="case-cta__title">Next Project</h3>
        <h2 class="case-cta__project">Project Name</h2>
        <a href="project2.html" class="case-cta__link">View Project →</a>
      </div>
    </section>
  </main>

  <!-- Footer -->
  <footer class="footer">
    <div class="footer__content">
      <div class="footer__left">
        <h3>Victor Cárdenas</h3>
        <p>Data Engineer & Scientist</p>
      </div>
      <div class="footer__right">
        <div class="footer__links">
          <a href="mailto:hello@victor.com" class="footer__link">Email</a>
          <a href="https://www.linkedin.com/in/victor-cardenas-g/" class="footer__link">LinkedIn</a>
          <a href="#" class="footer__link">GitHub</a>
        </div>
        <p class="footer__copyright">© 2025 Victor Cárdenas. All rights reserved.</p>
      </div>
    </div>
  </footer>

  <script src="script.js"></script>
  <script src="case-study.js"></script>
</body>
</html>